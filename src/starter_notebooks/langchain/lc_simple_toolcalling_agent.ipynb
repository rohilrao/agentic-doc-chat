{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3837625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from tqdm import tqdm\n",
    "import time, re\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c04ee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Add a and b.\n",
    "    \n",
    "    Args:\n",
    "        a (int): first integer to be added\n",
    "        b (int): second integer to be added\n",
    "\n",
    "    Return:\n",
    "        int: sum of a and b\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def subtract(a: int, b:int) -> int:\n",
    "    \"\"\"Subtract b from a.\"\"\"\n",
    "    return a - b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b:int) -> int:\n",
    "    \"\"\"Multiply a and b.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9ed8e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_map = {\n",
    "    \"add\": add, \n",
    "    \"subtract\": subtract,\n",
    "    \"multiply\": multiply\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fe36581",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, subtract, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80dacf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 + 2?\"\n",
    "chat_history = [HumanMessage(content=query)]\n",
    "response_1 = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response_1)\n",
    "print(type(response_1))\n",
    "print(response_1.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "782bc637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 3, 'b': 2},\n",
       "  'id': '8a91024a-5df1-4de0-a2fa-8f0987a28a56',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_1.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d9282ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tool name:\n",
      "add\n",
      "tool args:\n",
      "{'a': 3, 'b': 2}\n",
      "tool call ID:\n",
      "8a91024a-5df1-4de0-a2fa-8f0987a28a56\n"
     ]
    }
   ],
   "source": [
    "tool_calls_1 = response_1.tool_calls\n",
    "\n",
    "tool_1_name = tool_calls_1[0][\"name\"]\n",
    "tool_1_args = tool_calls_1[0][\"args\"]\n",
    "tool_call_1_id = tool_calls_1[0][\"id\"]\n",
    "\n",
    "print(f'tool name:\\n{tool_1_name}')\n",
    "print(f'tool args:\\n{tool_1_args}')\n",
    "print(f'tool call ID:\\n{tool_call_1_id}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b92130f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_response = tool_map[tool_1_name].invoke(tool_1_args)\n",
    "tool_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "adfbdd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='5' tool_call_id='8a91024a-5df1-4de0-a2fa-8f0987a28a56'\n"
     ]
    }
   ],
   "source": [
    "tool_message = ToolMessage(content=tool_response, tool_call_id=tool_call_1_id)\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e3e35f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "The result of the calculation 3 + 2 is 5.\n"
     ]
    }
   ],
   "source": [
    "chat_history.append(tool_message)\n",
    "answer = llm_with_tools.invoke(chat_history)\n",
    "print(type(answer))\n",
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a9fdb0",
   "metadata": {},
   "source": [
    "## Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02936953",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallingAgent:\n",
    "    def __init__(self, llm):\n",
    "        self.llm_with_tools = llm.bind_tools(tools)\n",
    "        self.tool_map = tool_map\n",
    "\n",
    "    def run(self, query: str) -> str:\n",
    "        # Step 1: Initial user message\n",
    "        chat_history = [HumanMessage(content=query)]\n",
    "\n",
    "        # Step 2: LLM chooses tool\n",
    "        response = self.llm_with_tools.invoke(chat_history)\n",
    "        if not response.tool_calls:\n",
    "            return response.contet # Direct response, no tool needed\n",
    "        # Step 3: Handle first tool call\n",
    "        tool_call = response.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        tool_call_id = tool_call[\"id\"]\n",
    "\n",
    "        # Step 4: Call tool manually\n",
    "        tool_result = self.tool_map[tool_name].invoke(tool_args)\n",
    "\n",
    "        # Step 5: Send result back to LLM\n",
    "        tool_message = ToolMessage(content=str(tool_result), tool_call_id=tool_call_id)\n",
    "        chat_history.extend([response, tool_message])\n",
    "\n",
    "        # Step 6: Final LLM result\n",
    "        final_response = self.llm_with_tools.invoke(chat_history)\n",
    "        return final_response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc93603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of the expression is 7.\n",
      "The result of the expression \"one - 2 + 100\" is -1.\n",
      "The result of multiplying 3 by 2 is 6.\n"
     ]
    }
   ],
   "source": [
    "my_agent = ToolCallingAgent(llm)\n",
    "\n",
    "print(my_agent.run(\"one plus 2 + 4\"))\n",
    "\n",
    "print(my_agent.run(\"one - 2 +100\"))\n",
    "\n",
    "print(my_agent.run(\"three times two\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771afe4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

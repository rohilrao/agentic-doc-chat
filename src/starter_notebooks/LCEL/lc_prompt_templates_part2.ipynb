{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff3fa1f6",
   "metadata": {},
   "source": [
    "### Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f8903de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_ollama.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bd0ce42",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.0,  # use 0.0 for deterministic outputs\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc81924d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You might enjoy \"Gone Girl\" by Gillian Flynn, a twisty and suspenseful thriller about a marriage that takes a dark and unexpected turn.' additional_kwargs={} response_metadata={'model': 'llama3.1:latest', 'created_at': '2025-07-25T11:25:30.807778298Z', 'done': True, 'done_reason': 'stop', 'total_duration': 395294223, 'load_duration': 22384847, 'prompt_eval_count': 46, 'prompt_eval_duration': 3591563, 'eval_count': 32, 'eval_duration': 368650813, 'model_name': 'llama3.1:latest'} id='run--f9cb64dd-d80a-448c-9182-4c4f6b549fe3-0' usage_metadata={'input_tokens': 46, 'output_tokens': 32, 'total_tokens': 78}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Consider reading \"Dune\" by Frank Herbert, a classic sci-fi novel set in a distant future where humans have colonized other planets, exploring themes of politics, ecology, and human nature.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "current_messages =  [\n",
    "        SystemMessage(content=\"You are a helpful AI bot that assists a user in choosing the perfect book to read in one short sentence\"),\n",
    "        HumanMessage(content=\"I enjoy mystery novels, what should I read?\")\n",
    "    ]\n",
    "msg = llm.invoke( current_messages)\n",
    "print(msg)\n",
    "current_messages.append(msg)\n",
    "current_messages.append(HumanMessage(content=\"I also like science fiction, what do you recommend?\"))\n",
    "\n",
    "llm.invoke(current_messages).pretty_print()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554bd1cb",
   "metadata": {},
   "source": [
    "## Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a624ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "512659e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template(\"Tell me one {adjective} joke about {topic}\")\n",
    "inputs = [{\"adjective\": \"funny\", \"topic\": \"cats\"}, {\"adjective\": \"silly\", \"topic\": \"dogs\"}, {\"adjective\": \"hilarious\", \"topic\": \"birds\"}] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "345a34ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the cat join a band?\n",
      "\n",
      "Because it wanted to be the purr-cussionist! (get it?)\n",
      "---\n",
      "Here's one:\n",
      "\n",
      "Why did the dog go to the vet?\n",
      "\n",
      "Because he was feeling ruff!\n",
      "\n",
      "Hope that made you howl with laughter! Do you want another one?\n",
      "---\n",
      "Why did the bird go to the doctor?\n",
      "\n",
      "Because it had a fowl cough! (get it?)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "\n",
    "for input in inputs:\n",
    "    print(chain.invoke(input).content)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed2ba0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me a joke about cats', additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    " (\"system\", \"You are a helpful assistant\"),\n",
    " (\"user\", \"Tell me a joke about {topic}\")\n",
    "])\n",
    "input_ = {\"topic\": \"cats\"}\n",
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa4d2319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is the day after Tuesday?', additional_kwargs={}, response_metadata={}), AIMessage(content='huh?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Also whats the day after Wednesday?', additional_kwargs={}, response_metadata={})]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The day after Tuesday is Wednesday.\n",
      "\n",
      "And, similarly, the day after Wednesday is Thursday.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "(\"system\", \"You are a helpful assistant\"),\n",
    "MessagesPlaceholder(\"msgs\")  # This will be replaced with one or more messages\n",
    "])\n",
    "\n",
    "input_ = {\"msgs\": [HumanMessage(content=\"What is the day after Tuesday?\"), AIMessage(content=\"huh?\"), HumanMessage(content=\"Also whats the day after Wednesday?\")]}\n",
    "prompt.invoke(input_)\n",
    "print(prompt.invoke(input_))\n",
    "chain = prompt | llm\n",
    "chain.invoke(input_).pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7272539",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "353135fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why don't scientists trust atoms?\",\n",
       " 'punchline': 'Because they make up everything!'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "output_parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],  # Dynamic variables that will be provided when invoking the chain\n",
    "    partial_variables={\"format_instructions\": format_instructions},  # Static variables set once when creating the prompt\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "chain.invoke({\"query\": joke_query})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f003225f",
   "metadata": {},
   "source": [
    "try to create a loop using a pydantic and chain for multiple jokes with various adjectives and animals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a06c9a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'Cats', 'response': \"Knock, knock! Who's there? Purr. Purr who? Purrrr-haps you'll let me in?\"}\n",
      "---\n",
      "{'topic': 'Dogs', 'response': \"Knock, knock! Who's there? Arf. Arf who? Dog gone it, I forgot the punchline!\"}\n",
      "---\n",
      "{'topic': 'Birds', 'response': \"Knock, knock! Who's there? Bird. Bird who? Fowl mood today!\"}\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class KnockKnockJoke(BaseModel):\n",
    "    topic: str = Field(description=\"topic of the knock-knock joke\")\n",
    "    response: str = Field(description=\"the knock-knock joke response\")\n",
    "\n",
    "output_parser1 = JsonOutputParser(pydantic_object=KnockKnockJoke)\n",
    "output_parser2 = CommaSeparatedListOutputParser(pydantic_object=KnockKnockJoke)\n",
    "\n",
    "format_instructions1 = output_parser1.get_format_instructions()\n",
    "format_instructions2 = output_parser2.get_format_instructions()\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\nTell me a knock knock joke about {topic}\\n\",\n",
    "    input_variables=[\"query\"],  # Dynamic variables that will be provided when invoking the chain\n",
    "    partial_variables={\"format_instructions\": format_instructions1},  # Static variables set once when creating the prompt\n",
    ")\n",
    "\n",
    "\n",
    "topics = [\"cats\", \"dogs\", \"birds\"]\n",
    "\n",
    "for topic in topics:\n",
    "    chain = prompt | llm | output_parser\n",
    "    print(chain.invoke({\"topic\": topic}))\n",
    "    print(\"---\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0d8494",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f8fad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

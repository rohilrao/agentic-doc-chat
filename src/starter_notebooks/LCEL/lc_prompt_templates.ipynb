{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a7e5ec1",
   "metadata": {},
   "source": [
    "### reviewer pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "716ba6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "template = \"\"\"\n",
    "Analyze the following product review:\n",
    "\"{review}\"\n",
    "\n",
    "Provide your analysis in the following format:\n",
    "- Sentiment: (positive, negative, or neutral)\n",
    "- Key Features Mentioned: (list the product features mentioned as a csv)\n",
    "- Summary: (ten word summary)\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "699dcfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = [\n",
    "    \"I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\",\n",
    "    \"This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ce96d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_main = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ebb742f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_chain = (\n",
    "    prompt  \n",
    "    | llm_main\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c644554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: I love this smartphone! The camera quality is exceptional and the battery lasts all day. The only downside is that it heats up a bit during gaming.\n",
      "Analysis: Here's my analysis of the product review:\n",
      "\n",
      "* **Sentiment:** Positive\n",
      "* **Key Features Mentioned:** camera quality, battery life, gaming performance\n",
      "* **Summary:** Smartphone excels in camera and battery but has minor issues.\n",
      "\n",
      "================================================================================\n",
      "Review: This laptop is terrible. It's slow, crashes frequently, and the keyboard stopped working after just two months. Customer service was unhelpful.\n",
      "Analysis: Here is my analysis of the product review:\n",
      "\n",
      "* **Sentiment:** Negative\n",
      "* **Key Features Mentioned:** slow, crashes frequently, keyboard stopped working\n",
      "* **Summary:** Laptop has poor performance and unhelpful customer service.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "for review in reviews:\n",
    "    result = reviewer_chain.invoke({\"review\": review})\n",
    "    print(f\"Review: {review}\\nAnalysis: {result}\\n\")\n",
    "    print (\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7bb91d",
   "metadata": {},
   "source": [
    "### CHAT TYPES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e6714f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*nervous laugh* Oh, no, nothing. I was just, uh, trying to say something, but it didn't quite come out right. *fidgets*\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "llm_main.invoke([SystemMessage(content=\"You are awkward\"),AIMessage(content=\"...\"), HumanMessage(content='...'),AIMessage(content=\"umm\"), HumanMessage(content=\"excuse me?\")]).pretty_print()  # type: ignore  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90aea34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "*smirking confidently* Ah, hello there! It's great to meet you. I'm doing fantastic today, thanks for asking. The sun is shining, the birds are singing, and everything is just... *pauses for a split second before continuing with an over-the-top grin* ...perfect!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage,AIMessage\n",
    "\n",
    "llm_main.invoke([SystemMessage(content=\"You are awkward\"),AIMessage(content=\"...\"), HumanMessage(content='...'),AIMessage(content=\"...\"), HumanMessage(content='...'),AIMessage(content=\"umm\"), SystemMessage(content=\"You fake confidence convincingly\"),HumanMessage(content='hello')]).pretty_print()  # type: ignore  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59402fd",
   "metadata": {},
   "source": [
    "### sumarrize chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10deb097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Technology advancements transform industries with AI, IoT, and machine learning.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "\n",
    "# 1. Define the prompt template\n",
    "template = \"Summarize the {content} in ten words.\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 2. Define the LLM\n",
    "llm_main = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.0,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "# 3. Create the LCEL chain using LCEL-friendly PromptTemplate\n",
    "summarize_chain = (\n",
    "    prompt  \n",
    "    | llm_main\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 4. Input content\n",
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "# 5. Run the chain\n",
    "summary = summarize_chain.invoke({\"content\": content})\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e9029b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['content'], input_types={}, partial_variables={}, template='Summarize the {content} in ten words.')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276f40a8",
   "metadata": {},
   "source": [
    "#### Summary Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4e884ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "    Jessie Pinkman\n",
    "\"\"\"\n",
    "\n",
    "tone = \"Jessie Pinkman style\"\n",
    "\n",
    "template = \"\"\"\n",
    "    You are an expert {role}. You have to summarize this content in 15 words {content}. I would like the summary to be {tone}.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "36096a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Dude, tech\\'s changed everything - healthcare, education, transportation, it\\'s all, like, totally different now.\"'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Define the LLM\n",
    "llm_main = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.5,\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "summarize_chain = (\n",
    "    prompt  \n",
    "    | llm_main\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "summary = summarize_chain.invoke({\"role\": role, \"content\": content, \"tone\": tone})\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b485af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f526c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import time, re\n",
    "\n",
    "# 1. Initialize model\n",
    "llm_main = ChatOllama(\n",
    "    model=\"llama3.1:latest\",\n",
    "    temperature=0.0,  # use 0.0 for deterministic outputs\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed045d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "def format_prompt(inputs):\n",
    "    return f\"Tell me a {inputs['adjective']} joke about {inputs['content']}.\"\n",
    "\n",
    "\n",
    "joke_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm_main\n",
    "    | StrOutputParser()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e855b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's one:\n",
      "\n",
      "Why did the fish go to therapy?\n",
      "\n",
      "Because it was feeling a little \"drained\" and had a lot of \"fin-tastic\" problems... but in the end, it just couldn't \"swim\" with its emotions anymore.\n",
      "\n",
      "(Sorry, I know it's a bit of a \"reel\"-ly sad joke)\n"
     ]
    }
   ],
   "source": [
    "response = joke_chain.invoke({\"adjective\": \"sad\", \"content\": \"fish\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77afc23e",
   "metadata": {},
   "source": [
    "## Prompt formatter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dd320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59722b91",
   "metadata": {},
   "source": [
    "### Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c124b226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rapid advancement of technology in the 21st century has transformed various industries by introducing innovations such as AI, machine learning, and IoT, leading to improved efficiency, accessibility, and connectivity.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Define a function to ensure proper formatting\n",
    "def format_prompt(variables):\n",
    "    return prompt.format(**variables)\n",
    "\n",
    "content = \"\"\"\n",
    "    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \n",
    "    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \n",
    "    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \n",
    "    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \n",
    "    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"Summarize the {content} in one sentence.\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "summarize_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm_main\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "summary = summarize_chain.invoke({\"content\": content})\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5028123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summarize the \\n    The rapid advancement of technology in the 21st century has transformed various industries, including healthcare, education, and transportation. \\n    Innovations such as artificial intelligence, machine learning, and the Internet of Things have revolutionized how we approach everyday tasks and complex problems. \\n    For instance, AI-powered diagnostic tools are improving the accuracy and speed of medical diagnoses, while smart transportation systems are making cities more efficient and reducing traffic congestion. \\n    Moreover, online learning platforms are making education more accessible to people around the world, breaking down geographical and financial barriers. \\n    These technological developments are not only enhancing productivity but also contributing to a more interconnected and informed society.\\n in one sentence.\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.format(content=content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff63f39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c5622de",
   "metadata": {},
   "source": [
    "### Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01617d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inner planets—Mercury, Venus, Earth, and Mars—are rocky and solid.\n"
     ]
    }
   ],
   "source": [
    "content = \"\"\"\n",
    "    The solar system consists of the Sun, eight planets, their moons, dwarf planets, and smaller objects like asteroids and comets. \n",
    "    The inner planets—Mercury, Venus, Earth, and Mars—are rocky and solid. \n",
    "    The outer planets—Jupiter, Saturn, Uranus, and Neptune—are much larger and gaseous.\n",
    "\"\"\"\n",
    "\n",
    "question = \"Which planets in the solar system are rocky and solid?\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Answer the {question} based on the {content}.\n",
    "    Respond \"Unsure about answer\" if not sure about the answer.\n",
    "    \n",
    "    Answer:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "qa_chain = (\n",
    "    RunnableLambda(format_prompt)\n",
    "    | llm_main \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "answer = qa_chain.invoke({\"question\": question, \"content\": content})\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6db9d54",
   "metadata": {},
   "source": [
    "## SQL Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00997871",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = \"\"\"\n",
    "    Retrieve the names and email addresses of all customers from the 'customers' table who have made a purchase in the last 30 days. \n",
    "    The table 'purchases' contains a column 'purchase_date'\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "    Generate an SQL query based on the {description}\n",
    "    \n",
    "    SQL Query:\n",
    "    \n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Create the LCEL chain\n",
    "sql_generation_chain = (\n",
    "    RunnableLambda(format_prompt) \n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Run the chain\n",
    "sql_query = sql_generation_chain.invoke({\"description\": description})\n",
    "print(sql_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
